<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Rademacher complexity | Data Science and Machine Learning</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Rademacher complexity" />
<meta name="author" content="Joao Gomes" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Rademacher complexity measures how a hypothesis correlates with noise. This gives a way to evaluate the capacity or complexity of a hypothesis class." />
<meta property="og:description" content="The Rademacher complexity measures how a hypothesis correlates with noise. This gives a way to evaluate the capacity or complexity of a hypothesis class." />
<link rel="canonical" href="http://localhost:4000/machine%20learning/2020/05/02/rademacher.html" />
<meta property="og:url" content="http://localhost:4000/machine%20learning/2020/05/02/rademacher.html" />
<meta property="og:site_name" content="Data Science and Machine Learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-02T00:00:00+02:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Rademacher complexity" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Joao Gomes"},"url":"http://localhost:4000/machine%20learning/2020/05/02/rademacher.html","headline":"Rademacher complexity","dateModified":"2020-05-02T00:00:00+02:00","datePublished":"2020-05-02T00:00:00+02:00","description":"The Rademacher complexity measures how a hypothesis correlates with noise. This gives a way to evaluate the capacity or complexity of a hypothesis class.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/machine%20learning/2020/05/02/rademacher.html"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css">
  <link rel="shortcut icon" type="image/png" href="/blog-data-science/favicon.png"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Science and Machine Learning" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Data Science and Machine Learning</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/categories/">Categories</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Rademacher complexity</h1>
    <p class="post-meta"><time class="dt-published" datetime="2020-05-02T00:00:00+02:00" itemprop="datePublished">
        May 2, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h3 id="table-of-contents"><strong>Table of contents</strong></h3>

<ol>
  <li><a href="#def">Definition</a></li>
  <li><a href="#bounds">Bounds</a></li>
</ol>

<p><a name="def"></a></p>
<h3 id="1-definition"><strong>1. Definition</strong></h3>

<p>The empirical Rademacher complexity of a hypothesis class $G={g}$ is defined as an average over the training set $S=(z_1,\ldots,z_m)$ in the following way:</p>

\[\hat{\mathcal{R}}(G)=E_{\sigma}\left[\text{sup}_{g\in G}\frac{1}{m}\sum_{i=1}^{m}\sigma_i g(z_i)\right]\]

<p>where $\sigma_i$ are $m$ independently and uniformly distributed random variables in the interval $[-1,1]$. Since $E(\sigma)=0$, we see that the average above is the correlation between $\sigma$ and $g(z)$. The Rademacher complexity, therefore, measures how well a hypothesis class correlates with noise. If a class has enough complexity, it will correlate more easily with noise and have higher Rademacher complexity.</p>

<p>The Rademacher complexity, rather than the empirical one, is in turn defined as the statistical average over the true distribution $D(z)^m$ on all the possible sets of size $m$:</p>

\[\mathcal{R}_m(G)=E_{\sim D^m}(\hat{\mathcal{R}}(G))\]

<p>Note that the expression above is explicitly dependent on $m$ because one cannot move the expectation in $z$ over to $g(z)$ inside the definition of the empirical Rademacher complexity.</p>

<p>For example, suppose we have a linear classifier in two dimensions 
$g(x\in \mathbb{R}^2)$
, which is a line that classifies points as ${-1,1}$ depending on whether the point is above or below the line. If we have up to three points, one can always choose a line that classifies all the points correctly. This is a consequence of the VC dimension of $\mathbb{R}^2$ being three. Then the above supremum is attained by picking a classifier $g$ such that</p>

\[\text{sup}_{g\in G} \sum_{i=1}^{m}\sigma_i g(z_i)=\sum_{i=1}^{m}|\sigma_i|\]

<p>, which is always possible if we have up to three points. The Rademacher complexity is simply</p>

\[\mathcal{R}_{m\leq 3}=E_{\sigma}|\sigma|\]

<p>, and thus independent of $m$. The same follows in higher dimensions. The Rademacher complexity is independent of $m$ if $m$ is less than the VC dimension. For $m$ bigger than the VC dimension, we can find the following bound.</p>

<p><a name="bounds"></a></p>
<h3 id="2-bounds"><strong>2. Bounds</strong></h3>

<p>One can determine several bounds on the Rademacher complexity. One of particular interest takes into account the growth function. Remember that the growth function $\Pi(m)$ is the maximal number of distinct ways of classifying a set of $m$ points $z_1,\ldots,z_m$ using an hypothesis class $\mathcal{H}$. In order to calculate this bound we need the following lemma:</p>

<p><em>Massart’s Lemma: let $A\subset \mathbb{R}^m$ be a finite set, and $r=\text{max}_{x\in A}|x|_2$, then</em></p>

\[E_{\sigma}\left[\frac{1}{m}\text{sup}_{x\in A}\sum_{i=1}^{m} \sigma_ix_i\right]\leq \frac{r\sqrt{2\ln|A|}}{m}\]

<p>where $\sigma_i$ are independent and uniformly distributed random variables in the interval $[-1,1]$. The proof goes by first using Jensen’s inequality:</p>

\[\begin{equation*}\begin{split}\exp(t E_{\sigma}[\text{sup}_{x\in A}\sum_{i=1}^{m} \sigma_i x_i])\leq E_{\sigma}\exp(t\text{sup}_{x\in A}\sum_{i=1}^m \sigma_i x_i)\end{split}\end{equation*}\]

<p>Now since the exponential function is monotically increasing we have that:</p>

\[E_{\sigma}\exp(t\text{sup}_{x\in A}\sum_{i=1}^m \sigma_i x_i)=E_{\sigma}\text{sup}_{x\in A}\exp(t\sum_{i=1}^m \sigma_i x_i)\leq \sum_{x\in A} E_{\sigma}\exp(t\sum_{i=1}^m \sigma_i x_i)\]

<p>Next we use the inequality nr. 2 from Hoeffding’s inequality post which states that for a random variable $w\in [a,b]$ with $E(w)=0$ we have:
\(E_w\exp(tw)\leq \exp(t^2(b-a)^2/8)\)</p>

<p>This means that:</p>

\[\sum_{x\in A} E_{\sigma}\exp(t\sum_{i=1}^m \sigma_i x_i)=\sum_{x\in A}\prod_iE_{\sigma_i}\exp(t \sigma_i x_i)\leq \sum_{x\in A} \exp(t^2x_i^2/2)\leq |A| \exp(t^2 r^2/2)\]

<p>where $|A|$ is the “size” of the set $A$ and 
$r^2=\text{max}_{x\in A}|x|_2$
Using this result in Eq.1 and taking the log on both sides of the inequality:</p>

\[E_{\sigma}[\text{sup}_{x\in A}\sum_{i=1}^{m} \sigma_i x_i]\leq \frac{\ln|A|}{t}+\frac{r^2}{2}t\]

<p>The optimal bound corresponds to</p>

\[t=\sqrt{2\ln|A|/r^2}\]

<p>which is the value where the function on the right side obtains its minimum. The final result is:</p>

\[E_{\sigma}[\text{sup}_{x\in A}\sum_{i=1}^{m} \sigma_i x_i]\leq r\sqrt{2\ln |A|}\]

<p>We can apply this result to determine a bound on the Rademacher complexity for hypothesis classes with target ${-1,1}$. So we have</p>

\[E_{D^m(z)}E_{\sigma}\left[\text{sup}_{g\in G}\frac{1}{m}\sum_{i=1}^{m}\sigma_i g(z_i)\right]\leq E_{D^m(z)}\frac{r}{m}\sqrt{2\ln |A|}\]

<p>We can easily calculate 
$r^2=\sum_i^mx_i^2=m$
 and thus $r=\sqrt{m}$. Moreover we know that, by definition, $|A|\leq \Pi(m)$, the growth function, and hence we find:</p>

\[\mathcal{R}_m\leq \sqrt{\frac{2\ln \Pi(m)}{m}}\]

  </div><a class="u-url" href="/machine%20learning/2020/05/02/rademacher.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Data Science and Machine Learning</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Joao Gomes</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/joaomvg"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">joaomvg</span></a></li><li><a href="https://www.linkedin.com/in/joaomvg"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">joaomvg</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Machine Learning algorithms in Python, statistics and cloud computing.</p>
      </div>
    </div>

  </div>

</footer>
</body>
  

</html>

 

<!-- CSS -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"/>

<!-- JavaScript -->
<script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body,{
    delimiters: [
      { left: '$$',  right: '$$',  display: true  },
      { left: '$',   right: '$',   display: false },
      { left: '\\[', right: '\\]', display: true  },
      { left: '\\(', right: '\\)', display: false }
  ]
  });">
</script>




